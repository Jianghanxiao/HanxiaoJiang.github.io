<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  <!-- Use the .htaccess and remove these lines to avoid edge case issues.
     More info: h5bp.com/i/378 -->
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />

  <!-- Our site title and description -->
  <title>Hanxiao Jiang | 蒋含啸</title>

  <meta name="generator" content="DocPad v6.79.4" />

  <!-- Mobile viewport optimized: h5bp.com/viewport -->
  <meta name="viewport" content="width=device-width" />

  <!-- Shims: IE6-8 support of HTML5 elements -->
  <!--[if lt IE 9]>
    <script async src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->

  <link  rel="stylesheet" href="/styles/twitter-bootstrap.css" /><link  rel="stylesheet" href="/styles/style.css" />
  <script  src="//cdnjs.cloudflare.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><script  src="//cdnjs.cloudflare.com/ajax/libs/modernizr/2.6.2/modernizr.min.js"></script><script  src="/scripts/bootstrap.min.js"></script><script  src="/scripts/script.js"></script>
</head>
<body>
  <div class="container">
    <section id="content" class="content">
      <div class="row">
  <h1>Hanxiao Jiang | 蒋含啸</h1>
  <hr>
  <div class="col-sm-8 pull-left" style="min-height: 280px; display: flex; flex-direction: column;">
    <p>
      I'm an undergraduate computer science student, who is in the dual degree program between <a href="https://www.zju.edu.cn/english/">Zhejiang University</a> and <a href="https://www.sfu.ca">Simon Fraser University</a>.  
      I will be starting Coop at <a href='https://www.daoai.ca'>DaoAI Robotics Inc</a> in Summer 2019 as an applied computer vision engineer. At the same time, I am a research assistant working with professor
      <a href="https://angelxuanchang.github.io">Angel Xuan Chang</a> and professor <a href="https://msavva.github.io">Manolis Savva</a> at <a href="https://www.sfu.ca">Simon Fraser University</a>.
      I worked on Interactiev models based on machine learning. In general, I am intersted in 3D model reconstruction, semantics of images and interpretion of machine learning.
    </p>
    <p>
    <h3>News</h3>
    <ul>
        
          <li>April, 2019 - I joined <a href='https://www.daoai.ca'>DaoAI Robotics Inc</a>.</li>
          <li>March, 2019 - Start studying with professor <a href="https://angelxuanchang.github.io">Angel Xuan Chang</a> and professor <a href="https://msavva.github.io">Manolis Savva</a>.</li>
          <li>May, 2018 - Got entrance scholarship, <a href="https://www.sfu.ca">Simon Fraser University</a>.</li>
          <li>November, 2017 - Got national scholarship, China.</li>
          <li>November, 2017 - Got first-class scholarship of academic excellence, <a href="https://www.zju.edu.cn/english/">Zhejiang University</a>.</li>
        
    </ul>
    </p>
  </div>
  <div class="col-sm-4 text-right pull-right">
    <img src="files/angel.jpg" alt="Angel Xuan Chang" width="150px"/>
    <div style="font-family:monospace;">
      angelx-{at}-cs-[dot]-stanford-"dot"-edu
    </div><br>
    Research Scientist<br/>
    <a href="http://eloquent.ai">Eloquent Labs</a><br/><br/>
    Assistant Professor (starting Fall 2019)<br/>
    School of Computing Science<br/>
    <a href="https://www.sfu.ca/computing.html">Simon Fraser University</a><br/>
    Canada CIFAR AI Chair<br/>
    <a href="https://scholar.google.com/citations?user=8gfs8XIAAAAJ&hl=en">Google Scholar</a>
  </div>
</div>
<br>

<div class="row">
  <div class="col-sm-12">

    
    <div class="panel panel-default">
      <div class="panel-heading">
        <h2>Publications</h2>
        <span class="badge badge-primary selectable" onclick="util.showAllPubs()">all</span>
        
          <span class="badge badge-primary selectable" onclick="util.showPubs('maintags', 'nlp')">nlp</span>
        
          <span class="badge badge-primary selectable" onclick="util.showPubs('maintags', 'vision')">vision</span>
        
          <span class="badge badge-primary selectable" onclick="util.showPubs('maintags', 'graphics')">graphics</span>
        
          <span class="badge badge-primary selectable" onclick="util.showPubs('maintags', 'hci')">hci</span>
        
      </div>
      <div class="panel-body">
      
              
          <div class="row paper vertical-center" id="pub_0" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://www.yifeishi.net/hierarchylayout.html"><img src="http://www.yifeishi.net/files/hierarchylayout1.JPG" alt="Hierarchy Denoising Recursive Autoencoders for 3D Scene Layout Prediction" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://www.yifeishi.net/hierarchylayout.html">
                Hierarchy Denoising Recursive Autoencoders for 3D Scene Layout Prediction
                </a>
              </h4>
              
                
                <a href="http://www.yifeishi.net/">Yifei Shi</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                
                <a href="https://kevinkaixu.net/">Kai Xu</a><br>
              
              Accepted to CVPR 2019, arXiv:1903.03757 [cs.CV]<br>
              <a href="https://arxiv.org/pdf/1903.03757">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://www.yifeishi.net/hierarchylayout.html">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_1" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="https://cs.stanford.edu/~kaichun/partnet/"><img src="https://cs.stanford.edu/~kaichun/partnet/images/teaser.png" alt="PartNet: A Large-scale Benchmark for Fine-grained and Hierarchical Part-level 3D Object Understanding" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="https://cs.stanford.edu/~kaichun/partnet/">
                PartNet: A Large-scale Benchmark for Fine-grained and Hierarchical Part-level 3D Object Understanding
                </a>
              </h4>
              
                
                <a href="https://cs.stanford.edu/~kaichun">Kaichun Mo</a>, 
              
                
                <a href="http://cseweb.ucsd.edu/~shz338/">Shilin Zhu</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://cs.stanford.edu/~ericyi/">Li Yi</a>, 
              
                
                <a href="http://acsweb.ucsd.edu/~stripath/">Subarna Tripathi</a>, 
              
                
                <a href="http://geometry.stanford.edu/member/guibas/">Leonidas Guibas</a>, 
              
                
                <a href="http://cseweb.ucsd.edu/~haosu/">Hao Su</a><br>
              
              Accepted to CVPR 2019, arXiv:1812.02713 [cs.CV]<br>
              <a href="https://arxiv.org/abs/1812.02713">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="https://youtu.be/7pEuoxmb-MI">video</a> 
              
              
              
              
              
              
              
               | <a href="https://cs.stanford.edu/~kaichun/partnet/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_2" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="https://niessnerlab.org/projects/avetisyan2018scan2cad.html"><img src="https://niessnerlab.org/papers/2018/z3scan2cad/teaser.jpg" alt="Scan2CAD: Learning CAD Model Alignment in RGB-D Scans" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="https://niessnerlab.org/projects/avetisyan2018scan2cad.html">
                Scan2CAD: Learning CAD Model Alignment in RGB-D Scans
                </a>
              </h4>
              
                
                <a href="https://niessnerlab.org/members/armen_avetisyan/profile.html">Armen Avetisyan</a>, 
              
                
                <a href="https://niessnerlab.org/members/manuel_dahnert/profile.html">Manuel Dahnert</a>, 
              
                
                <a href="http://cs.stanford.edu/people/adai">Angela Dai</a>, 
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://graphics.stanford.edu/~niessner/">Matthias Nießner</a><br>
              
              Accepted to CVPR 2019, arXiv:1811.11187 [cs.CV]<br>
              <a href="https://arxiv.org/pdf/1811.11187.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://www.youtube.com/watch?v=PiHSYpgLTfA">video</a> 
              
              
              
              
              
              
              
               | <a href="https://niessnerlab.org/projects/avetisyan2018scan2cad.html">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_3" data-maintags="graphics,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="https://dritchie.github.io/pdf/deepsynth.pdf"><img src="http://msavva.github.io/files/deepsynth.png" alt="Deep Convolutional Priors for Indoor Scene Synthesis" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Deep Convolutional Priors for Indoor Scene Synthesis
                
              </h4>
              
                
                Kai Wang, 
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://dritchie.github.io/">Daniel Ritchie</a><br>
              
              SIGGRAPH 2018<br>
              <a href="https://dritchie.github.io/pdf/deepsynth.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="https://github.com/brownvc/deep-synth">code</a> 
              
              
              
              
              
              
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_4" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://text2shape.stanford.edu/"><img src="http://msavva.github.io/files/text2shape.png" alt="Text2Shape: Generating Shapes from Natural Language by Learning Joint Embeddings" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://text2shape.stanford.edu/">
                Text2Shape: Generating Shapes from Natural Language by Learning Joint Embeddings
                </a>
              </h4>
              
                
                Kevin Chen, 
              
                
                <a href="https://chrischoy.github.io/">Christopher B. Choy</a>, 
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a>, 
              
                
                <a href="http://cvgl.stanford.edu/silvio/">Silvio Savarese</a><br>
              
              Proceedings of ACCV 2018, arXiv:1803.08495 [cs.CV]<br>
              <a href="https://arxiv.org/abs/1803.08495">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="https://github.com/kchen92/text2shape/">code</a> 
              
              
              
              
              
              
              
               | <a href="http://text2shape.stanford.edu/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_5" data-maintags="robotics,preprint">
            <div class="col-sm-3 paper-img">
            
              <a href="https://www.minosworld.org/"><img src="https://github.com/minosworld/minos/raw/master/docs/img/video_thumbnail.png" alt="MINOS: Multimodal Indoor Simulator for Navigation in Complex Environments" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="https://www.minosworld.org/">
                MINOS: Multimodal Indoor Simulator for Navigation in Complex Environments
                </a>
              </h4>
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://dosovits.github.io/">Alexey Dosovitskiy</a>, 
              
                
                <a href="http://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a>, 
              
                
                <a href="http://vladlen.info/">Vladlen Koltun</a><br>
              
              arXiv:1712.03931 [cs.LG]<br>
              <a href="https://arxiv.org/abs/1712.03931">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="https://github.com/minosworld/minos">code</a> 
              
               | <a href="https://youtu.be/c0mL9K64q84">video</a> 
              
              
              
              
              
              
              
               | <a href="https://www.minosworld.org/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_6" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://im2pano3d.cs.princeton.edu/"><img src="http://im2pano3d.cs.princeton.edu/teaser.jpg" alt="Im2Pano3D: Extrapolating 360 Structure and Semantics Beyond the Field of View" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://im2pano3d.cs.princeton.edu/">
                Im2Pano3D: Extrapolating 360 Structure and Semantics Beyond the Field of View
                </a>
              </h4>
              
                
                <a href="http://vision.princeton.edu/people/shurans/">Shuran Song</a>, 
              
                
                <a href="http://www.cs.princeton.edu/~andyz/">Andy Zeng</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                
                <a href="http://cvgl.stanford.edu/silvio/">Silvio Savarese</a>, 
              
                
                <a href="http://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a><br>
              
              Proceedings of CVPR 2018, arXiv:1712.04569 [cs.CV]<br>
              <a href="https://arxiv.org/abs/1712.04569">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://im2pano3d.cs.princeton.edu/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_7" data-maintags="nlp,resources">
            <div class="col-sm-3 paper-img">
            
              <a href="http://compling.hss.ntu.edu.sg/events/2018-gwc/pdfs/GWC2018_paper_66.pdf"><img src="files/wordnetLink.png" alt="Linking WordNet to 3D Shapes" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Linking WordNet to 3D Shapes
                
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                Rishi Mago, 
              
                
                Pranav Krishna, 
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                
                <a href="https://www.cs.princeton.edu/~fellbaum/">Christiane Fellbaum</a><br>
              
              Proceedings of Global WordNet Conference 2018<br>
              <a href="http://compling.hss.ntu.edu.sg/events/2018-gwc/pdfs/GWC2018_paper_66.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_8" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://cseweb.ucsd.edu/~haosu/papers/3dv2017_attribute_transfer.pdf"><img src="http://msavva.github.io/files/attributeTransfer.png" alt="Cross-modal Attribute Transfer for Rescaling 3D Models" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Cross-modal Attribute Transfer for Rescaling 3D Models
                
              </h4>
              
                
                <a href="https://linsats.github.io/">Lin Shao</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://cseweb.ucsd.edu/~haosu/">Hao Su</a>, 
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                
                <a href="http://geometry.stanford.edu/member/guibas/">Leonidas Guibas</a><br>
              
              Proceedings of 3DV 2017<br>
              <a href="http://cseweb.ucsd.edu/~haosu/papers/3dv2017_attribute_transfer.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_9" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="https://niessner.github.io/Matterport/"><img src="http://msavva.github.io/files/matterport3d.png" alt="Matterport3D: Learning from RGB-D Data in Indoor Environments" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="https://niessner.github.io/Matterport/">
                Matterport3D: Learning from RGB-D Data in Indoor Environments
                </a>
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://cs.stanford.edu/people/adai">Angela Dai</a>, 
              
                
                <a href="http://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a>, 
              
                
                <a href="http://www.cs.princeton.edu/~mhalber/">Maciej Halber</a>, 
              
                
                <a href="http://graphics.stanford.edu/~niessner/">Matthias Nießner</a>, 
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                
                <a href="http://vision.princeton.edu/people/shurans/">Shuran Song</a>, 
              
                
                <a href="http://www.cs.princeton.edu/~andyz/">Andy Zeng</a>, 
              
                
                <a href="http://robots.princeton.edu/people/yindaz/">Yinda Zhang</a><br>
              
              Proceedings of 3DV 2017, arXiv:1709.06158 [cs.CV]<br>
              <a href="https://arxiv.org/pdf/1709.06158.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="https://niessner.github.io/Matterport/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_10" data-maintags="vision,preprint">
            <div class="col-sm-3 paper-img">
            
              <a href="https://arxiv.org/pdf/1704.02393.pdf"><img src="http://msavva.github.io/files/viewsets.png" alt="Learning Where to Look: Data-Driven Viewpoint Set Selection for 3D Scenes" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Learning Where to Look: Data-Driven Viewpoint Set Selection for 3D Scenes
                
              </h4>
              
                
                <a href="http://www.kylegenova.com/">Kyle Genova</a>, 
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a><br>
              
              arXiv:1704.02393 [cs.CV]<br>
              <a href="https://arxiv.org/pdf/1704.02393.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_11" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://www.scan-net.org/"><img src="http://www.scan-net.org/img/annotations.png" alt="ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://www.scan-net.org/">
                ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes
                </a>
              </h4>
              
                
                <a href="http://cs.stanford.edu/people/adai">Angela Dai</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                
                <a href="http://www.cs.princeton.edu/~mhalber/">Maciej Halber</a>, 
              
                
                <a href="http://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a>, 
              
                
                <a href="http://graphics.stanford.edu/~niessner/">Matthias Nießner</a><br>
              
              Proceedings of CVPR 2017, arXiv:1702.04405 [cs.CV]<br>
              <a href="https://arxiv.org/pdf/1702.04405.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="https://github.com/ScanNet/ScanNet">code</a> 
              
               | <a href="http://www.youtube.com/watch?v=Olx4OnoZWQQ">video</a> 
              
              
              
              
              
              
              
               | <a href="http://www.scan-net.org/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_12" data-maintags="vision,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://vision.princeton.edu/projects/2016/SSCNet/"><img src="http://vision.princeton.edu/projects/2016/SSCNet/thumbnail.jpg" alt="Semantic Scene Completion from a Single Depth Image" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://vision.princeton.edu/projects/2016/SSCNet/">
                Semantic Scene Completion from a Single Depth Image
                </a>
              </h4>
              
                
                <a href="http://vision.princeton.edu/people/shurans/">Shuran Song</a>, 
              
                
                <a href="http://yf.io/">Fisher Yu</a>, 
              
                
                <a href="http://www.cs.princeton.edu/~andyz/">Andy Zeng</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                
                <a href="http://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a><br>
              
              Proceedings of CVPR 2017, arXiv:1611.08974 [cs.CV]<br>
              <a href="https://arxiv.org/pdf/1611.08974v1.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://vision.princeton.edu/projects/2016/SSCNet/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_13" data-maintags="nlp,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://nlp.stanford.edu/~muzny/quoteli.html"><img src="files/quote-attribution.png" alt="A Two-stage Sieve Approach to Quote Attribution" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://nlp.stanford.edu/~muzny/quoteli.html">
                A Two-stage Sieve Approach to Quote Attribution
                </a>
              </h4>
              
                
                <a href="http://nlp.stanford.edu/~muzny/">Grace Muzny</a>, 
              
                
                Michael Fang, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://www.stanford.edu/~jurafsky/">Dan Jurafsky</a><br>
              
              Proceedings of EACL 2017<br>
              <a href="">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/~muzny/quoteli.html">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_14" data-maintags="preprint">
            <div class="col-sm-3 paper-img">
            
              <a href="http://arxiv.org/abs/1703.00061.pdf"><img src="http://msavva.github.io/files/scenesuggest.png" alt="SceneSuggest: Context-driven 3D Scene Design" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                SceneSuggest: Context-driven 3D Scene Design
                
              </h4>
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://graphics.stanford.edu/~maneesh/">Maneesh Agrawala</a><br>
              
              arXiv:1703.00061 [cs.CG], March 2017<br>
              <a href="http://arxiv.org/abs/1703.00061.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="https://dovahkiin.stanford.edu/fuzzybox/scene-suggest.html">demo</a> 
              
              
              
              
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_15" data-maintags="preprint">
            <div class="col-sm-3 paper-img">
            
              <a href="http://arxiv.org/abs/1703.00050.pdf"><img src="http://msavva.github.io/files/sceneseer.png" alt="SceneSeer: 3D Scene Design with Natural Language" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                SceneSeer: 3D Scene Design with Natural Language
                
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://www.mihaileric.com/">Mihail Eric</a>, 
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              arXiv:1703.00050 [cs.CG], March 2017<br>
              <a href="http://arxiv.org/abs/1703.00050.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="https://dovahkiin.stanford.edu/fuzzybox/text2scene.html">demo</a> 
              
              
              
              
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_16" data-maintags="hci,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="https://research.tableau.com/paper/eviza-natural-language-interface-visual-analysis"><img src="https://research.tableau.com/sites/default/files/uploads/eviza_teaser.png" alt="Eviza: A Natural Language Interface for Visual Analysis" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="https://research.tableau.com/paper/eviza-natural-language-interface-visual-analysis">
                Eviza: A Natural Language Interface for Visual Analysis
                </a>
              </h4>
              
                
                <a href="https://research.tableau.com/user/vidya-setlur">Vidya Setlur</a>, 
              
                
                <a href="https://research.tableau.com/user/sarah-battersby">Sarah E. Battersby</a>, 
              
                
                <a href="https://research.tableau.com/user/melanie-tory">Melanie Tory</a>, 
              
                
                <a href="https://research.tableau.com/user/rich-gossweiler">Rich Gossweiler</a>, 
              
                <b>
                Angel X. Chang<br></b>
              
              UIST 2016<br>
              <a href="https://research.tableau.com/sites/default/files/uist4832-setlurA_0.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="https://research.tableau.com/paper/eviza-natural-language-interface-visual-analysis">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_17" data-maintags="graphics,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://graphics.stanford.edu/projects/pigraphs/"><img src="http://graphics.stanford.edu/projects/pigraphs/pigraphs.png" alt="PiGraphs: Learning Interaction Snapshots from Observations" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://graphics.stanford.edu/projects/pigraphs/">
                PiGraphs: Learning Interaction Snapshots from Observations
                </a>
              </h4>
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://graphics.stanford.edu/~hanrahan/">Pat Hanrahan</a>, 
              
                
                <a href="http://graphics.stanford.edu/~mdfisher/">Matthew Fisher</a>, 
              
                
                <a href="http://graphics.stanford.edu/~niessner/">Matthias Nießner</a><br>
              
              SIGGRAPH 2016<br>
              <a href="http://graphics.stanford.edu/projects/pigraphs/">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://graphics.stanford.edu/projects/pigraphs/">bib</a> 
              
              
              
              
              
              
              
               | <a href="http://graphics.stanford.edu/projects/pigraphs/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_18" data-maintags="nlp,preprint">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Evaluating the word-expert approach for Named-Entity Disambiguation
                
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://nlp.stanford.edu/valentin/">Valentin I. Spitkovsky</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a>, 
              
                
                <a href="http://ixa2.si.ehu.es/~jipagbee/">Eneko Agirre</a><br>
              
              arXiv:1603.04767 [cs.CL], March 2016<br>
              <a href="http://arxiv.org/pdf/1603.04767v1">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_19" data-maintags="thesis">
            <div class="col-sm-3 paper-img">
            
              <a href="https://purl.stanford.edu/vg064sy5087"><img src="files/text2scene.png" alt="Text to 3D scene generation" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Text to 3D scene generation
                
              </h4>
              
                <b>
                Angel X. Chang<br></b>
              
              Ph.D. dissertation, Department of Computer Science, Stanford University, 2015<br>
              <a href="https://purl.stanford.edu/vg064sy5087">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_20" data-maintags="3d,preprint">
            <div class="col-sm-3 paper-img">
            
              <a href="http://shapenet.cs.stanford.edu/"><img src="files/shapenet.png" alt="ShapeNet: An Information-Rich 3D Model Repository" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://shapenet.cs.stanford.edu/">
                ShapeNet: An Information-Rich 3D Model Repository
                </a>
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a>, 
              
                
                <a href="http://geometry.stanford.edu/member/guibas/">Leonidas Guibas</a>, 
              
                
                <a href="http://graphics.stanford.edu/~hanrahan/">Pat Hanrahan</a>, 
              
                
                <a href="http://www.cs.utexas.edu/~huangqx/">Qixing Huang</a>, 
              
                
                Zimo Li, 
              
                
                <a href="http://cvgl.stanford.edu/silvio/">Silvio Savarese</a>, 
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                
                <a href="http://vision.princeton.edu/people/shurans/">Shuran Song</a>, 
              
                
                <a href="http://cseweb.ucsd.edu/~haosu/">Hao Su</a>, 
              
                
                <a href="http://www.jianxiongxiao.com/">Jianxiong Xiao</a>, 
              
                
                <a href="https://cs.stanford.edu/~ericyi/">Li Yi</a>, 
              
                
                <a href="http://yf.io/">Fisher Yu</a><br>
              
              arXiv:1512.03012 [cs.GR], Dec 2015<br>
              <a href="http://arxiv.org/pdf/1512.03012v1">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://shapenet.cs.stanford.edu/resources/shapenet.bib">bib</a> 
              
               | <a href="https://github.com/ShapeNet">code</a> 
              
              
              
              
              
              
              
               | <a href="http://shapenet.cs.stanford.edu/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_21" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
              <a href="http://nlp.stanford.edu/software/scenegraph-parser.shtml"><img src="files/twomen.png" alt="Generating Semantically Precise Scene Graphs from Textual Descriptions for Improved Image Retrieval" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://nlp.stanford.edu/software/scenegraph-parser.shtml">
                Generating Semantically Precise Scene Graphs from Textual Descriptions for Improved Image Retrieval
                </a>
              </h4>
              
                
                <a href="http://sebschu.com/">Sebastian Schuster</a>, 
              
                
                <a href="http://www.ranjaykrishna.com/">Ranjay Krishna</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://vision.stanford.edu/feifeili/">Li Fei-Fei</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              In Proceedings of the Fourth Workshop on Vision and Language (VL15)<br>
              <a href="http://nlp.stanford.edu/~sebschu/pubs/schuster-krishna-chang-feifei-manning-vl15.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/~sebschu/pubs/schuster-krishna-chang-feifei-manning-vl15.bib">bib</a> 
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/software/scenegraph-parser.shtml">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_22" data-maintags="vision,workshop">
            <div class="col-sm-3 paper-img">
            
              <a href="http://graphics.stanford.edu/projects/semgeo/"><img src="files/semgeo.png" alt="Semantically-Enriched 3D Models for Common-sense Knowledge" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://graphics.stanford.edu/projects/semgeo/">
                Semantically-Enriched 3D Models for Common-sense Knowledge
                </a>
              </h4>
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://graphics.stanford.edu/~hanrahan/">Pat Hanrahan</a><br>
              
              CVPR 2015 Vision meets Cognition Workshop<br>
              <a href="http://graphics.stanford.edu/projects/semgeo/semgeo.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://graphics.stanford.edu/projects/semgeo/semgeo.bib">bib</a> 
              
              
              
              
              
              
              
              
              
               | <a href="http://graphics.stanford.edu/projects/semgeo/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_23" data-maintags="nlp,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://nlp.stanford.edu/data/text2scene.shtml"><img src="files/lexground.png" alt="Text to 3D Scene Generation with Rich Lexical Grounding" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://nlp.stanford.edu/data/text2scene.shtml">
                Text to 3D Scene Generation with Rich Lexical Grounding
                </a>
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://wmonroeiv.github.io/">Will Monroe</a>, 
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                
                <a href="http://web.stanford.edu/~cgpotts/">Christopher Potts</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              Proceedings of ACL 2015<br>
              <a href="http://nlp.stanford.edu/pubs/chang-acl2015-lexground.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/pubs/chang-acl2015-lexground.bib">bib</a> 
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/data/text2scene.shtml">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_24" data-maintags="graphics,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://graphics.stanford.edu/projects/scenegrok/"><img src="files/scenegrok.png" alt="SceneGrok: Inferring Action Maps in 3D Environments" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://graphics.stanford.edu/projects/scenegrok/">
                SceneGrok: Inferring Action Maps in 3D Environments
                </a>
              </h4>
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://graphics.stanford.edu/~hanrahan/">Pat Hanrahan</a>, 
              
                
                <a href="http://graphics.stanford.edu/~mdfisher/">Matthew Fisher</a>, 
              
                
                <a href="http://graphics.stanford.edu/~niessner/">Matthias Nießner</a><br>
              
              Proceedings of SIGGRAPH Asia 2014<br>
              <a href="http://graphics.stanford.edu/projects/scenegrok/scenegrok.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://graphics.stanford.edu/projects/scenegrok/scenegrok.bib">bib</a> 
              
              
              
              
              
              
              
              
              
               | <a href="http://graphics.stanford.edu/projects/scenegrok/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_25" data-maintags="graphics,workshop">
            <div class="col-sm-3 paper-img">
            
              <a href="http://graphics.stanford.edu/projects/sizes/"><img src="files/sizes.png" alt="On Being the Right Scale: Sizing Large Collections of 3D Models" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://graphics.stanford.edu/projects/sizes/">
                On Being the Right Scale: Sizing Large Collections of 3D Models
                </a>
              </h4>
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://graphics.stanford.edu/~gilbo/">Gilbert Bernstein</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a>, 
              
                
                <a href="http://graphics.stanford.edu/~hanrahan/">Pat Hanrahan</a><br>
              
              SIGGRAPH Asia 2014 Workshop on Indoor Scene Understanding: Where Graphics meets Vision<br>
              <a href="http://graphics.stanford.edu/projects/sizes/sizes.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://graphics.stanford.edu/projects/sizes/sizes.bib">bib</a> 
              
              
              
              
              
              
              
              
              
               | <a href="http://graphics.stanford.edu/projects/sizes/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_26" data-maintags="nlp,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://nlp.stanford.edu/projects/text2scene.shtml"><img src="files/spatialLearning.png" alt="Learning Spatial Knowledge for Text to 3D Scene Generation" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://nlp.stanford.edu/projects/text2scene.shtml">
                Learning Spatial Knowledge for Text to 3D Scene Generation
                </a>
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP 2014)<br>
              <a href="http://nlp.stanford.edu/pubs/spatial-emnlp2014.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/pubs/spatial-emnlp2014.bib">bib</a> 
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/projects/text2scene.shtml">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_27" data-maintags="vision,workshop">
            <div class="col-sm-3 paper-img">
            
              <a href="files/fpic2014.pdf"><img src="files/fpic2014.png" alt="Learning Affordance Maps by Observing Interactions" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Learning Affordance Maps by Observing Interactions
                
              </h4>
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://graphics.stanford.edu/~mdfisher/">Matthew Fisher</a>, 
              
                
                <a href="http://graphics.stanford.edu/~niessner/">Matthias Nießner</a>, 
              
                
                <a href="http://graphics.stanford.edu/~hanrahan/">Pat Hanrahan</a><br>
              
              CVPR 2014 Workshop on Functionality, Physics, Intentionality and Causality<br>
              <a href="files/fpic2014.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="files/fpic2014.bib">bib</a> 
              
              
              
              
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_28" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
              <a href="http://nlp.stanford.edu/projects/text2scene.shtml"><img src="files/interactiveLearning.png" alt="Interactive Learning of Spatial Knowledge for Text to 3D Scene Generation" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://nlp.stanford.edu/projects/text2scene.shtml">
                Interactive Learning of Spatial Knowledge for Text to 3D Scene Generation
                </a>
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              Proceedings of the ACL 2014 Workshop on Interactive Language Learning, Visualization, and Interfaces<br>
              <a href="http://nlp.stanford.edu/pubs/scenegen-aclviz2014.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/pubs/scenegen-aclviz2014.bib">bib</a> 
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/projects/text2scene.shtml">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_29" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
              <a href="http://nlp.stanford.edu/projects/text2scene.shtml"><img src="files/semanticParsing.png" alt="Semantic Parsing for Text to 3D Scene Generation" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://nlp.stanford.edu/projects/text2scene.shtml">
                Semantic Parsing for Text to 3D Scene Generation
                </a>
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              Proceedings of the ACL 2014 Workshop on Semantic Parsing<br>
              <a href="http://nlp.stanford.edu/pubs/scenegen-sp2014.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/pubs/scenegen-sp2014.bib">bib</a> 
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/projects/text2scene.shtml">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_30" data-maintags="hci,conference">
            <div class="col-sm-3 paper-img">
            
              <a href="http://graphics.stanford.edu/projects/transphoner/"><img src="files/transphoner.png" alt="TransPhoner: Automated Mnemonic Keyword Generation" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://graphics.stanford.edu/projects/transphoner/">
                TransPhoner: Automated Mnemonic Keyword Generation
                </a>
              </h4>
              
                
                <a href="http://graphics.stanford.edu/~msavva/">Manolis Savva</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a>, 
              
                
                <a href="http://graphics.stanford.edu/~hanrahan/">Pat Hanrahan</a><br>
              
              Proceedings of CHI 2014<br>
              <a href="http://graphics.stanford.edu/projects/transphoner/TransPhoner.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://graphics.stanford.edu/projects/transphoner/TransPhoner.bib">bib</a> 
              
              
              
              
              
              
              
               | <a href="http://graphics.stanford.edu/projects/transphoner/">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_31" data-maintags="nlp,preprint">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://nlp.stanford.edu/software/tokensregex.shtml">
                TokensRegex: Defining cascaded regular expressions over tokens
                </a>
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              Stanford University Technical Report<br>
              <a href="http://nlp.stanford.edu/pubs/tokensregex-tr-2014.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/pubs/tokensregex-tr-2014.bib">bib</a> 
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/software/tokensregex.shtml">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_32" data-maintags="nlp,journal">
            <div class="col-sm-3 paper-img">
            
              <a href="http://nlp.stanford.edu/software/dcoref.shtml"><img src="files/corefSieves.png" alt="Deterministic coreference resolution based on entity-centric, precision-ranked rules" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://nlp.stanford.edu/software/dcoref.shtml">
                Deterministic coreference resolution based on entity-centric, precision-ranked rules
                </a>
              </h4>
              
                
                Heeyoung Lee, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://nlp.yvespeirsman.be/">Yves Peirsman</a>, 
              
                
                <a href="http://www.usna.edu/Users/cs/nchamber/">Nathanael Chambers</a>, 
              
                
                <a href="http://www.surdeanu.name/mihai/">Mihai Surdeanu</a>, 
              
                
                <a href="http://www.stanford.edu/~jurafsky/">Dan Jurafsky</a><br>
              
              In Computational Linguistics 39(4)<br>
              <a href="http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00152">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/software/dcoref.shtml">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_33" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Stanford's 2013 KBP System
                
              </h4>
              
                
                <a href="http://cs.stanford.edu/~angeli/">Gabor Angeli</a>, 
              
                
                <a href="http://arun.chagantys.org/">Arun Chaganty</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="https://sites.google.com/site/kevinreschke/">Kevin Reschke</a>, 
              
                
                Julie Tibshirani, 
              
                
                Jean Y. Wu, 
              
                
                <a href="https://obastani.github.io/">Osbert Bastani</a>, 
              
                
                Keith Siilats, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              In Proceedings of the Sixth Text Analysis Conference (TAC 2014)<br>
              <a href="http://stanford.edu/~angeli/papers/2014-tac-kbp.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_34" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                SUTime: Evaluation in TempEval-3
                
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013)<br>
              <a href="http://aclweb.org/anthology/S/S13/S13-2013.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_35" data-maintags="nlp,conference">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Joint Entity and Event Coreference Resolution across Documents
                
              </h4>
              
                
                Heeyoung Lee, 
              
                
                <a href="http://clic.ub.edu/users/marta-recasens">Marta Recasens</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://www.surdeanu.name/mihai/">Mihai Surdeanu</a>, 
              
                
                <a href="http://www.stanford.edu/~jurafsky/">Dan Jurafsky</a><br>
              
              Proceedings of the Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2012)<br>
              <a href="http://nlp.stanford.edu/pubs/emnlp2012-coref.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/pubs/emnlp2012-coref.bib">bib</a> 
              
              
              
              
              
              
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_36" data-maintags="nlp,resources">
            <div class="col-sm-3 paper-img">
            
              <a href="http://nlp.stanford.edu/software/sutime.shtml"><img src="files/sutime.png" alt="SUTime: A Library for Recognizing and Normalizing Time Expressions." class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://nlp.stanford.edu/software/sutime.shtml">
                SUTime: A Library for Recognizing and Normalizing Time Expressions.
                </a>
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              In Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC 2012)<br>
              <a href="http://nlp.stanford.edu/pubs/lrec2012-sutime.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/pubs/lrec2012-sutime.bib">bib</a> 
              
               | <a href="http://nlp.stanford.edu/pubs/lrec2012-sutime-poster.pdf">poster</a> 
              
              
              
               | <a href="http://nlp.stanford.edu:8080/sutime">demo</a> 
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/software/sutime.shtml">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_37" data-maintags="nlp,resources">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                A Cross-Lingual Dictionary for English Wikipedia Concepts
                
              </h4>
              
                
                <a href="http://nlp.stanford.edu/valentin/">Valentin I. Spitkovsky</a>, 
              
                <b>
                Angel X. Chang<br></b>
              
              In Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC 2012)<br>
              <a href="http://nlp.stanford.edu/pubs/crosswikis.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/pubs/crosswikis.bib">bib</a> 
              
               | <a href="http://nlp.stanford.edu/pubs/crosswikis-slides.pdf">slides</a> 
              
               | <a href="https://plus.google.com/117790530324740296539/posts/VSjc4KYpug2">post</a> 
              
               | <a href="http://nlp.stanford.edu/pubs/crosswikis-data.tar.bz2">data</a> 
              
              
              
              
              
              
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_38" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Stanford's Distantly-Supervised Slot-Filling System
                
              </h4>
              
                
                <a href="http://www.surdeanu.name/mihai/">Mihai Surdeanu</a>, 
              
                
                <a href="http://www.cs.stanford.edu/people/sonal/">Sonal Gupta</a>, 
              
                
                John Bauer, 
              
                
                <a href="http://nlp.stanford.edu/~mcclosky/">David McClosky</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://nlp.stanford.edu/valentin/">Valentin I. Spitkovsky</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              In Proceedings of the Fourth Text Analysis Conference (TAC 2011)<br>
              <a href="http://nlp.stanford.edu/pubs/kbp2011-slotfilling.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/pubs/kbp2011-slotfilling.bib">bib</a> 
              
               | <a href="http://nlp.stanford.edu/pubs/kbp_trigger_words.txt">data</a> 
              
              
              
              
              
              
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_39" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Strong Baselines for Cross-Lingual Entity Linking
                
              </h4>
              
                
                <a href="http://nlp.stanford.edu/valentin/">Valentin I. Spitkovsky</a>, 
              
                <b>
                Angel X. Chang<br></b>
              
              In Proceedings of the Fourth Text Analysis Conference (TAC 2011)<br>
              <a href="http://nlp.stanford.edu/pubs/kbp2011-crosslinking.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/pubs/kbp2011-crosslinking.bib">bib</a> 
              
              
              
              
              
              
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_40" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Stanford-UBC Entity Linking at TAC-KBP, Again
                
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://nlp.stanford.edu/valentin/">Valentin I. Spitkovsky</a>, 
              
                
                <a href="http://ixa2.si.ehu.es/~jipagbee/">Eneko Agirre</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              In Proceedings of the Fourth Text Analysis Conference (TAC 2011)<br>
              <a href="http://nlp.stanford.edu/pubs/kbp2011-entitylinking.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/pubs/kbp2011-entitylinking.bib">bib</a> 
              
              
              
              
              
              
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_41" data-maintags="nlp,conference">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Unsupervised Dependency Parsing without Gold Part-of-Speech Tags
                
              </h4>
              
                
                <a href="http://nlp.stanford.edu/valentin/">Valentin I. Spitkovsky</a>, 
              
                
                Hiyan Alshawi, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://www.stanford.edu/~jurafsky/">Dan Jurafsky</a><br>
              
              In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP 2011)<br>
              <a href="http://nlp.stanford.edu/pubs/goldtags.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/pubs/goldtags.bib">bib</a> 
              
               | <a href="http://nlp.stanford.edu/pubs/goldtags-poster.pdf">poster</a> 
              
               | <a href="http://nlp.stanford.edu/pubs/goldtags-data.tar.bz2">data</a> 
              
              
              
              
              
              
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_42" data-maintags="nlp,conference">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                <a href="http://nlp.stanford.edu/software/dcoref.shtml">
                Stanford's Multi-Pass Sieve Coreference Resolution System at the CoNLL-2011 Shared Task
                </a>
              </h4>
              
                
                Heeyoung Lee, 
              
                
                <a href="http://nlp.yvespeirsman.be/">Yves Peirsman</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://www.usna.edu/Users/cs/nchamber/">Nathanael Chambers</a>, 
              
                
                <a href="http://www.surdeanu.name/mihai/">Mihai Surdeanu</a>, 
              
                
                <a href="http://www.stanford.edu/~jurafsky/">Dan Jurafsky</a><br>
              
              In Proceedings of the CoNLL-2011 Shared Task<br>
              <a href="http://nlp.stanford.edu/pubs/conllst2011-coref.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/pubs/conllst2011-coref.bib">bib</a> 
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/software/dcoref.shtml">webpage</a> 
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_43" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                A Simple Distant Supervision Approach for the TAC-KBP Slot Filling Task
                
              </h4>
              
                
                <a href="http://www.surdeanu.name/mihai/">Mihai Surdeanu</a>, 
              
                
                <a href="http://nlp.stanford.edu/~mcclosky/">David McClosky</a>, 
              
                
                Julie Tibshirani, 
              
                
                John Bauer, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://nlp.stanford.edu/valentin/">Valentin I. Spitkovsky</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              In Proceedings of the Third Text Analysis Conference (TAC 2010)<br>
              <a href="http://nlp.stanford.edu/pubs/kbp2010-slotfilling.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/pubs/kbp2010-slotfilling.bib">bib</a> 
              
               | <a href="http://nlp.stanford.edu/pubs/kbp2010-slotfilling-slides.pptx">slides</a> 
              
              
              
              
              
              
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_44" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Stanford-UBC Entity Linking at TAC-KBP
                
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://nlp.stanford.edu/valentin/">Valentin I. Spitkovsky</a>, 
              
                
                <a href="http://www.ai.sri.com/people/yeh/">Eric Yeh</a>, 
              
                
                <a href="http://ixa2.si.ehu.es/~jipagbee/">Eneko Agirre</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a><br>
              
              In Proceedings of the Third Text Analysis Conference (TAC 2010)<br>
              <a href="http://nlp.stanford.edu/pubs/kbp2010-entitylinking.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/pubs/kbp2010-entitylinking.bib">bib</a> 
              
               | <a href="http://nlp.stanford.edu/pubs/kbp2010-entitylinking-poster.pdf">poster</a> 
              
              
              
              
              
              
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_45" data-maintags="nlp,workshop">
            <div class="col-sm-3 paper-img">
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                Stanford-UBC at TAC-KBP
                
              </h4>
              
                
                <a href="http://ixa2.si.ehu.es/~jipagbee/">Eneko Agirre</a>, 
              
                <b>
                Angel X. Chang, </b>
              
                
                <a href="http://www.stanford.edu/~jurafsky/">Dan Jurafsky</a>, 
              
                
                <a href="http://nlp.stanford.edu/manning/">Christopher D. Manning</a>, 
              
                
                <a href="http://nlp.stanford.edu/valentin/">Valentin I. Spitkovsky</a>, 
              
                
                <a href="http://www.ai.sri.com/people/yeh/">Eric Yeh</a><br>
              
              In Proceedings of the Second Text Analysis Conference (TAC 2009)<br>
              <a href="http://nlp.stanford.edu/pubs/subctackbp.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
               | <a href="http://nlp.stanford.edu/pubs/subctackbp.bib">bib</a> 
              
               | <a href="http://nlp.stanford.edu/pubs/subctackbp-slides.pdf">slides</a> 
              
              
              
              
              
              
              
              
            </div>
          </div>
        
          <div class="row paper vertical-center" id="pub_46" data-maintags="msic,journal">
            <div class="col-sm-3 paper-img">
            
              <a href="pubs/dragonbound.pdf"><img src="files/dragonCurve.png" alt="The Fractal Geometry of the Boundary of Dragon Curves" class="img-responsive" style="width: 300px;"/></a>
              &nbsp;
            
            </div>
            <div class="col-sm-9">
              <h4 class="red">
                
                The Fractal Geometry of the Boundary of Dragon Curves
                
              </h4>
              
                <b>
                Angel X. Chang, </b>
              
                
                Tianrong Zhang<br>
              
              In Journal of Recreational Mathematics 30 (1), 9-22<br>
              <a href="pubs/dragonbound.pdf">pdf</a> 
              
              
              
              
              
              
              
              
              
              
              
              
              
               | <a href="pubs/dragonbound.bib">bib</a> 
              
              
              
              
              
              
            </div>
          </div>
        
  
      </div>
    </div>

  </div>
</div>
    </section>
    <footer>
      <p class="pull-right">
        Last updated at 2019-03-24T17:11:51.321Z
      </p>
    </footer>
  </div><!-- /container -->
</body>
</html>
